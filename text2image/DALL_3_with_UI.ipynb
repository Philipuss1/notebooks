{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DALL-3 with UI",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2zclUVMKBkz"
      },
      "source": [
        "#**DALL-3**\n",
        "\n",
        "by Philipuss#4066\n",
        "\n",
        "Everything was taken from [this repo](https://github.com/Jack000/DALLE-pytorch) by Jack000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zihXNUvSItJO",
        "cellView": "form"
      },
      "source": [
        "#@title <font color=\"lightgreen\" size=\"+3\">‚Üê</font> <font size=\"+2\">üîÜ</font> **Set Up [RUN ME]** <font size=\"+2\">üîÜ</font>\n",
        "\n",
        "download_main_libraries = True #@param {type:\"boolean\"}\n",
        "download_vqgan = True #@param {type:\"boolean\"}\n",
        "download_dalle = True #@param {type:\"boolean\"}\n",
        "\n",
        "if download_main_libraries:\n",
        "  !git clone https://github.com/openai/CLIP                  &>/dev/null\n",
        "  !pip install -e ./CLIP                                     &>/dev/null\n",
        "  !git clone https://github.com/Jack000/DALLE-pytorch        &>/dev/null\n",
        "  !pip install -e ./DALLE-pytorch                            &>/dev/null\n",
        "\n",
        "if download_vqgan:\n",
        "  !curl -L -o vqgan.yaml --http1.1 'https://heibox.uni-heidelberg.de/f/b24d14998a8d4f19a34f/?dl=1'  &> /dev/null\n",
        "  !curl -L -o vqgan.pt   --http1.1 'https://heibox.uni-heidelberg.de/f/34a747d5765840b5a99d/?dl=1'  &> /dev/null\n",
        "if download_dalle:\n",
        "  !curl -OL --http1.1 'https://dall-3.com/models/dalle/bpe.model'       &> /dev/null\n",
        "  !curl -OL --http1.1 'https://dall-3.com/models/dalle/dalle-latest.pt' &> /dev/null\n",
        "\n",
        "from einops import repeat\n",
        "from einops import rearrange\n",
        "import math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "%cd /content/DALLE-pytorch\n",
        "import torch\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torchvision.transforms import functional as TF\n",
        "from dalle_pytorch import DiscreteVAE, OpenAIDiscreteVAE, VQGanVAE, DALLE\n",
        "from dalle_pytorch.tokenizer import tokenizer, HugTokenizer, YttmTokenizer, ChineseTokenizer\n",
        "%cd ../\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "sys.path.append('./CLIP')\n",
        "sys.path.append('./DALLE-pytorch')\n",
        "tokenizer = YttmTokenizer('bpe.model')\n",
        "load_obj = torch.load('dalle-latest.pt', map_location='cpu')\n",
        "dalle_params, vae_params, weights = load_obj.pop('hparams'), load_obj.pop('vae_params'), load_obj.pop('weights')\n",
        "dalle_params.pop('vae', None)\n",
        "vae = VQGanVAE('vqgan.pt', 'vqgan.yaml')\n",
        "dalle = DALLE(vae = vae, **dalle_params).to(device)\n",
        "dalle.load_state_dict(weights)\n",
        "\n",
        "print(\"Finished!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_hPr2LaIRrE",
        "cellView": "form"
      },
      "source": [
        "#@title <font color=\"lightgreen\" size=\"+3\">‚Üê</font> <font size=\"+2\">üéá</font> **Run DALL-3** <font size=\"+2\">üéá</font>\n",
        "\n",
        "prompt = 'a photo of a chicken.' #@param {type:\"string\"}\n",
        "randomness = 0.84 #@param {type:\"number\"}\n",
        "top_p =  0.8#@param {type:\"number\"}\n",
        "batch_size = 1 #@param {type:\"number\"}\n",
        "batches = 1 #@param {type:\"number\"}\n",
        "\n",
        "prompt = prompt.lower()\n",
        "text_tokens = tokenizer.tokenize([prompt], dalle.text_seq_len).to(device)\n",
        "text_tokens = repeat(text_tokens, '() n -> b n', b = batch_size)\n",
        "outputs = []\n",
        "image_tokens = []\n",
        "for i in range(batches):\n",
        "  out, tok = dalle.generate_images(text_tokens, temperature=randomness, top_p_thresh = top_p, return_tokens = True)  \n",
        "  outputs.append(out)\n",
        "  for j in range(batch_size):\n",
        "    pimg = TF.to_pil_image(out[j])\n",
        "    display(pimg)\n",
        "    pimg.save('image' + str(i) + '.png')\n",
        "    image_tokens.append(tok[j])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}