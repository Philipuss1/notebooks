{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Philipuss's ruDALLE Notebook",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FEIJ7CUUBVJ"
      },
      "source": [
        "#**ruDALLE** <font size=\"+2\">ü•ë</font>\n",
        "\n",
        "This is a 1.3 billion parameter model for Russian, recreating OpenAI's DALL¬∑E, a model capable of generating arbitrary images from a text prompt that describes the desired result.\n",
        "\n",
        "The generation pipeline includes ruDALL-E, ruCLIP for ranging results, and a superresolution model. You can use automatic translation into Russian to create desired images with ruDALL-E.\n",
        "\n",
        "Model was trained by Sber AI and SberDevices teams.\n",
        "\n",
        "English2Russian translator is Facebook-FAIR's WMT'19 model.\n",
        "\n",
        "\n",
        "\n",
        "Added a nice GUI & cleaned things, added an English2Russian translator, added a super-res script (from [this notebook](https://colab.research.google.com/drive/1_evIaGmeo-RXWJrmavB3hR4UBhJJV5xL)) made by danielrussruss#6125, combined the image prompt notebook from the official ruDALLE repo with this one, Philipuss#4066."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "RXHbpMh1QlWd"
      },
      "source": [
        "#@title GPU Info <font size=\"+2\">üìä</font>\n",
        "import multiprocessing\n",
        "import torch\n",
        "from psutil import virtual_memory\n",
        "\n",
        "ram_gb = round(virtual_memory().total / 1024**3, 1)\n",
        "\n",
        "print('CPU:', multiprocessing.cpu_count())\n",
        "print('RAM GB:', ram_gb)\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA version:\", torch.version.cuda)\n",
        "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device.type)\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFBMm0cVRV-E",
        "cellView": "form"
      },
      "source": [
        "#@title <font color=\"lightgreen\" size=\"+3\">‚Üê</font> **Installing and initializing libraries** <font size=\"+2\">üé°</font>\n",
        "\n",
        "!pip install rudalle           > /dev/null\n",
        "!pip install transformers      > /dev/null\n",
        "\n",
        "from rudalle.pipelines import generate_images, show, super_resolution, cherry_pick_by_clip\n",
        "from rudalle.image_prompts import ImagePrompts\n",
        "from rudalle import get_rudalle_model, get_tokenizer, get_vae, get_realesrgan, get_ruclip\n",
        "from rudalle.utils import seed_everything\n",
        "import requests\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
        "\n",
        "device = 'cuda'\n",
        "dalle = get_rudalle_model('Malevich', pretrained=True, fp16=True, device=device)\n",
        "try:\n",
        "    realesrgan, tokenizer, ruclip, ruclip_processor\n",
        "except NameError:\n",
        "    realesrgan = get_realesrgan('x4', device=device)\n",
        "    tokenizer = get_tokenizer()\n",
        "    vae = get_vae().to(device)\n",
        "    ruclip, ruclip_processor = get_ruclip('ruclip-vit-base-patch32-v5')\n",
        "    ruclip = ruclip.to(device)\n",
        "\n",
        "\n",
        "\n",
        "mname = \"facebook/wmt19-en-ru\"\n",
        "enru_tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
        "enru_model = FSMTForConditionalGeneration.from_pretrained(mname)\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "import more_itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from rudalle import utils\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from rudalle.dalle.utils import divide, split_tensor_along_last_dim\n",
        "\n",
        "@torch.jit.script\n",
        "def gelu_impl(x):\n",
        "    \"\"\"OpenAI's gelu implementation.\"\"\"\n",
        "    return 0.5 * x * (1.0 + torch.tanh(0.7978845608028654 * x * (1.0 + 0.044715 * x * x)))\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    return gelu_impl(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "GdOYJvwZSB-D"
      },
      "source": [
        "#@title # <font color=\"lightgreen\" size=\"+3\">‚Üê</font> **Generate Images** <font size=\"+2\">üé®</font>\n",
        "#@markdown Type your prompt and run this cell to let the magic happen\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "prompt = \"A photo of a male Philipuss. Pencil sketch.\" #@param {type:\"string\"}\n",
        "translate_english_to_russian = True #@param {type:\"boolean\"}\n",
        "image_count =  6#@param {type:\"number\"}\n",
        "seed = -1 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **ADVANCED SETTINGS**\n",
        "\n",
        "num_resolutions = 7 #@param {type:\"integer\"}\n",
        "top_K = 1024 #@param {type:\"number\"}\n",
        "top_P = 0.92 #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "#@markdown **Image Prompt Settings**\n",
        "image_prompt = \"\" #@param {type:\"string\"}\n",
        "crop_up = 10 #@param {type:\"number\"}\n",
        "crop_left = 0 #@param {type:\"number\"}\n",
        "crop_right = 0 #@param {type:\"number\"}\n",
        "crop_down = 0 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "\n",
        "#########################################################\n",
        "\n",
        "\n",
        "if translate_english_to_russian:\n",
        "  input_ids = enru_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "  outputs = enru_model.generate(input_ids)\n",
        "  decoded = enru_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  prompt = decoded\n",
        "\n",
        "print(prompt)\n",
        "text = prompt\n",
        "\n",
        "\n",
        "if seed == -1:\n",
        "  #Thanks to kendrick#9537 for spotting the problem\n",
        "  seed = random.randint(0, 2**32-1)\n",
        "\n",
        "\n",
        "pil_images = []\n",
        "scores = []\n",
        "\n",
        "if image_prompt == \"\":\n",
        "  seed_everything(seed)\n",
        "\n",
        "  for top_k, top_p, images_num in tqdm([(top_K, top_P, image_count)][::-1][:num_resolutions]):\n",
        "      _pil_images, _scores = generate_images(text, tokenizer, dalle, vae, top_k=top_k, images_num=images_num, top_p=top_p)\n",
        "      pil_images += _pil_images\n",
        "      scores += _scores\n",
        "      show([pil_image for pil_image, score in sorted(zip(pil_images, scores), key=lambda x: -x[1])], 6)\n",
        "else:\n",
        "  #Image_Prompt = Image.open(requests.get(image_prompt, stream=True).raw).resize((256, 256))\n",
        "  Image_Prompt = Image.open(image_prompt).resize((256, 256))\n",
        "  borders = {'up': crop_up, 'left': crop_left, 'right': crop_right, 'down': crop_down}\n",
        "  image_prompts = [\n",
        "      ImagePrompts(Image_Prompt, borders, vae, torch.device('cuda'), crop_first=True)\n",
        "  ]\n",
        "\n",
        "  for image_prompt in image_prompts:\n",
        "      total_image_prompts = []\n",
        "      seed_everything(42)\n",
        "      for top_k, top_p, images_num in [\n",
        "          (top_K, top_P, image_count),\n",
        "      ]:\n",
        "        _pil_images, _ = generate_images(\n",
        "            text,\n",
        "            tokenizer,\n",
        "            dalle,\n",
        "            vae,\n",
        "            top_k=top_K,\n",
        "            images_num=images_num,\n",
        "            image_prompts=image_prompt,\n",
        "            top_p=top_P\n",
        "        )\n",
        "        pil_images += _pil_images\n",
        "      #top_images, _ = cherry_pick_by_clip(pil_images, text, ruclip, ruclip_processor, device=device, count=5)\n",
        "      #total_image_prompts += super_resolution(top_images, realesrgan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "CEGx8sK0QwDp"
      },
      "source": [
        "#@title <font color=\"lightgreen\" size=\"+3\">‚Üê</font> **Show Best Outputs** <font size=\"+2\">ü•á</font>\n",
        "\n",
        "top_images_count = -1 #@param {type:\"number\"}\n",
        "\n",
        "if top_images_count == -1:\n",
        "  top_images_count = image_count\n",
        "\n",
        "top_images, clip_scores = cherry_pick_by_clip(pil_images, prompt, ruclip, ruclip_processor, device=device, count=top_images_count)\n",
        "show(top_images, top_images_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-sfSSBzQpar",
        "cellView": "form"
      },
      "source": [
        "#@title <font color=\"lightgreen\" size=\"+3\">‚Üê</font> **Increase Resolution** <font size=\"+2\">‚ú®</font>\n",
        "\n",
        "upscale_images_count = -1 #@param {type:\"number\"}\n",
        "\n",
        "if upscale_images_count == -1:\n",
        "  upscale_images_count = image_count\n",
        "\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "top_images, clip_scores = cherry_pick_by_clip(pil_images, text, ruclip, ruclip_processor, device=device, count=upscale_images_count)\n",
        "realesrgan = get_realesrgan('x4', device=device)\n",
        "sr_images = super_resolution(top_images, realesrgan)\n",
        "timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "os.makedirs(f'dalle_outputs/{timestring}', exist_ok=True)\n",
        "\n",
        "for pil_image, score in sorted(zip(sr_images, clip_scores), key=lambda x: -x[1]):\n",
        "    pil_image.save(f'dalle_outputs/{timestring}/rudalle_{score}.png')\n",
        "    print(f'CLIP score: {score}')\n",
        "    display.display(pil_image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}